{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d03075e9-668f-48e5-a669-b136b77a1aac",
      "metadata": {},
      "source": [
        "## Welcome to the FLAIR-GG Coordinates by species Analytics Notebook\n",
        "\n",
        "Please run the first cell to set-up the analytics environment\n",
        "\n",
        "In the second cell, we have pre-filled a basic analytics, to show you how to access and manipulate the data that was retrieved from the FLAIR-GG Virtual Platform.  \n",
        "\n",
        "Fill in the \"key = 'XXXXXXX' with the secret key for your federated exploration output, and then... go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe0cbee-b01d-46a0-b529-9685621a233b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pyodide_kernel\n",
        "\n",
        "%pip install ipywidgets==8.1.1\n",
        "%pip install ipyevents==2.0.2\n",
        "%pip install ipympl==0.9.4\n",
        "%pip install ipycanvas==0.13.2\n",
        "%pip install ipyleaflet==0.18.2\n",
        "%pip install plotly==5.24.0\n",
        "%pip install bqplot==0.12.45\n",
        "%pip install altair\n",
        "%pip install pandas\n",
        "%pip install requests\n",
        "%pip install seaborn\n",
        "%pip install matplotlib\n",
        "%pip install geopandas\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "import pyodide_http\n",
        "import ssl\n",
        "import json\n",
        "import requests\n",
        "import urllib3\n",
        "import urllib.parse\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d531371-85ca-417d-b279-9fa94d48bf8a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import io   \n",
        "\n",
        "key = \"XXXXXXXX\"   # your secret key from the FLAIR-GG Virtual Platform\n",
        "# key = \"630e5b25-bc4e-4568-833c-8b8bc7303dcb\"   # a valid SPARQL results output, if you need it :-)\n",
        "\n",
        "url = \"https://bgv.cbgp.upm.es/DAV/home/LDP/FLAIR/{}\".format(key)\n",
        "\n",
        "\n",
        "response = requests.get(url)\n",
        "response = json.loads(response.content)\n",
        "# print(response)\n",
        "for provider in response.keys():\n",
        "    print(\"Provider: {}\".format(provider))\n",
        "    data = response[provider]\n",
        "    df = pd.read_csv(io.StringIO(data), sep=\",\")    \n",
        "    df\n",
        "    print(df)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9b2718-86c8-4467-95bc-1680dee0b995",
      "metadata": {},
      "source": [
        "Let's remove entries that contain a subspecies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08848f6d-c693-4a50-9c81-d795b1e7c5f1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = df[~df[\"scientific_name\"].str.contains(\"subsp.\")]\n",
        "sci_name = df[\"scientific_name\"].unique()\n",
        "if len(sci_name) != 1:\n",
        "    raise ValueError(f\"Expected one scientific name, found {len(sci_name)}: {sci_name}\")\n",
        "scientific_name = sci_name[0]\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0408ca7-8912-41f1-a9b4-30a0e1604d4c",
      "metadata": {},
      "source": [
        "The coordinates are in a different format, let's transform them to decimal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0338a204-f3a4-4170-80cd-7f4f08573088",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def dms_to_decimal(coord):\n",
        "    # Example input: \"3408--N\" or \"00203--W\"\n",
        "    coord = coord.strip()\n",
        "    # split numeric part and hemisphere\n",
        "    hemisphere = coord[-1]\n",
        "    numbers = coord[:-3]  # remove \"--X\"\n",
        "    \n",
        "    # degrees are all but last two digits, minutes are last two\n",
        "    deg = int(numbers[:-2])\n",
        "    minutes = int(numbers[-2:])\n",
        "    \n",
        "    decimal = deg + minutes / 60\n",
        "    \n",
        "    if hemisphere in [\"S\", \"W\"]:\n",
        "        decimal = -decimal\n",
        "    \n",
        "    return decimal\n",
        "\n",
        "df[\"decimalLatitude\"] = df[\"latitude\"].apply(dms_to_decimal)\n",
        "df[\"decimalLongitude\"] = df[\"longitude\"].apply(dms_to_decimal)\n",
        "df_germplasm = df\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4ae29b-3fac-483c-99e2-10721b8fcb6c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Helper: read shapefile/geojson and ensure CRS\n",
        "# ================================\n",
        "def read_shapefile(path):\n",
        "    return gpd.read_file(path, encoding=\"utf-8\").to_crs(\"EPSG:4326\")\n",
        "\n",
        "# ================================\n",
        "# Helper: filter points within a community polygon\n",
        "# ================================\n",
        "def filter_within_community(gdf_points, communities_file, community_name):\n",
        "    gdf_comm = read_shapefile(communities_file)\n",
        "    comm = gdf_comm[gdf_comm[\"NAME_1\"].str.strip().str.lower() == community_name.strip().lower()]\n",
        "    if comm.empty:\n",
        "        raise ValueError(f\"Community '{community_name}' not found!\")\n",
        "    return gdf_points[gdf_points.within(comm.geometry.union_all())]\n",
        "\n",
        "# ================================\n",
        "# 1️⃣ Query GBIF directly using requests\n",
        "# ================================\n",
        "def query_gbif_by_community_bbox(species_name, community_name, communities_file, limit=500):\n",
        "    gdf_comm = read_shapefile(communities_file)\n",
        "    community = gdf_comm[gdf_comm[\"NAME_1\"].str.strip().str.lower() == community_name.strip().lower()]\n",
        "    if community.empty:\n",
        "        raise ValueError(f\"Community '{community_name}' not found!\")\n",
        "\n",
        "    # Bounding box for GBIF query\n",
        "    minx, miny, maxx, maxy = community.total_bounds\n",
        "    polygon_wkt = f\"POLYGON(({minx} {miny}, {minx} {maxy}, {maxx} {maxy}, {maxx} {miny}, {minx} {miny}))\"\n",
        "\n",
        "    url = \"https://api.gbif.org/v1/occurrence/search\"\n",
        "    params = {\n",
        "        \"scientificName\": species_name,\n",
        "        \"geometry\": polygon_wkt,  # no manual encoding\n",
        "        \"limit\": limit,\n",
        "        \"hasCoordinate\": True,\n",
        "        \"fields\": \"decimalLatitude,decimalLongitude,country,stateProvince,municipality\"\n",
        "    }\n",
        "\n",
        "    r = requests.get(url, params=params)\n",
        "    r.raise_for_status()\n",
        "    res = r.json()\n",
        "\n",
        "    df = pd.DataFrame(res.get(\"results\", []))\n",
        "    if df.empty:\n",
        "        print(\"No GBIF occurrences found.\")\n",
        "        return gpd.GeoDataFrame(columns=[\"decimalLatitude\", \"decimalLongitude\"], geometry=[])\n",
        "\n",
        "    df = df.reindex(columns=[\"decimalLatitude\", \"decimalLongitude\", \"country\", \"stateProvince\", \"municipality\"])\n",
        "    gdf_occ = gpd.GeoDataFrame(\n",
        "        df,\n",
        "        geometry=[Point(xy) for xy in zip(df[\"decimalLongitude\"], df[\"decimalLatitude\"])],\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "\n",
        "    # Filter exactly inside community polygon\n",
        "    gdf_occ = filter_within_community(gdf_occ, communities_file, community_name)\n",
        "    return gdf_occ\n",
        "\n",
        "# ================================\n",
        "# 2️⃣ Assign province & municipality (levels 2 & 3)\n",
        "# ================================\n",
        "def assign_admin_levels(gdf_occurrences, provinces_file, municipalities_file):\n",
        "    gdf = gdf_occurrences.copy()\n",
        "    for shapefile, level_name, col_name in [\n",
        "        (provinces_file, \"NAME_2\", \"province_assigned\"),\n",
        "        (municipalities_file, \"NAME_3\", \"municipality_assigned\")\n",
        "    ]:\n",
        "        gdf_s = read_shapefile(shapefile)\n",
        "        gdf = gpd.sjoin(gdf, gdf_s, how=\"left\", predicate=\"within\")\n",
        "        gdf[col_name] = gdf[level_name]\n",
        "        if \"index_right\" in gdf.columns:\n",
        "            gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    return gdf\n",
        "\n",
        "# ================================\n",
        "# 3️⃣ Coverage comparison\n",
        "# ================================\n",
        "def calculate_coverage_with_names(gdf_gbif, gdf_germplasm, plot=False):\n",
        "    # Provinces\n",
        "    gbif_provinces = set(gdf_gbif[\"province_assigned\"].dropna().unique())\n",
        "    germ_provinces = set(gdf_germplasm[\"province_assigned\"].dropna().unique())\n",
        "    province_coverage = (\n",
        "        len(germ_provinces & gbif_provinces) / len(gbif_provinces) * 100\n",
        "        if gbif_provinces else 0\n",
        "    )\n",
        "\n",
        "    # Municipalities\n",
        "    gbif_munis = set(gdf_gbif[\"municipality_assigned\"].dropna().unique())\n",
        "    germ_munis = set(gdf_germplasm[\"municipality_assigned\"].dropna().unique())\n",
        "    municipality_coverage = (\n",
        "        len(germ_munis & gbif_munis) / len(gbif_munis) * 100\n",
        "        if gbif_munis else 0\n",
        "    )\n",
        "\n",
        "    if plot:\n",
        "        labels = [\"Province coverage\", \"Municipality coverage\"]\n",
        "        values = [province_coverage, municipality_coverage]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(6, 5))\n",
        "        bars = ax.bar(labels, values, color=[\"steelblue\", \"seagreen\"])\n",
        "\n",
        "        # --- dynamic ylim headroom ---\n",
        "        max_val = max(values)\n",
        "        ylim_top = max_val * 1.1 if max_val >= 95 else 100\n",
        "        ax.set_ylim(0, ylim_top)\n",
        "\n",
        "        ax.set_ylabel(\"Coverage (%)\")\n",
        "        ax.set_title(\"Coverage of Germplasm vs GBIF Occurrences\")\n",
        "\n",
        "        # Add value labels above bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f\"{height:.1f}%\",\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # slight offset above bar\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha=\"center\", va=\"bottom\", fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return province_coverage, municipality_coverage, gbif_provinces, germ_provinces, gbif_munis, germ_munis\n",
        "\n",
        "# ================================\n",
        "# 4️⃣ Plot dataset\n",
        "# ================================\n",
        "def plot_dataset_separately(\n",
        "    gdf_occurrences,\n",
        "    provinces_file,\n",
        "    municipalities_file=None,\n",
        "    communities_file=None,\n",
        "    community_name=None,\n",
        "    title_prefix=\"Occurrences\"\n",
        "):\n",
        "    if gdf_occurrences.empty:\n",
        "        print(f\"No points to plot for {title_prefix}.\")\n",
        "        return\n",
        "\n",
        "    gdf_prov = read_shapefile(provinces_file)\n",
        "    gdf_muni = read_shapefile(municipalities_file) if municipalities_file else None\n",
        "    gdf_comm = read_shapefile(communities_file) if communities_file else None\n",
        "\n",
        "    # Color by province\n",
        "    provinces = gdf_occurrences[\"province_assigned\"].dropna().unique()\n",
        "    cmap = plt.get_cmap(\"tab20\")\n",
        "    province_colors = {prov: cmap(i % 20) for i, prov in enumerate(provinces)}\n",
        "    gdf_occurrences[\"color\"] = gdf_occurrences[\"province_assigned\"].map(province_colors)\n",
        "\n",
        "    # --- Make a single figure with 2 axes ---\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # --- Full map of Spain ---\n",
        "    gdf_prov.boundary.plot(ax=ax1, color=\"black\", linewidth=0.5)\n",
        "    if gdf_muni is not None:\n",
        "        gdf_muni.boundary.plot(ax=ax1, color=\"gray\", linewidth=0.2, alpha=0.3)\n",
        "    for prov, color in province_colors.items():\n",
        "        subset = gdf_occurrences[gdf_occurrences[\"province_assigned\"] == prov]\n",
        "        subset.plot(ax=ax1, color=color, markersize=30, alpha=0.7, label=prov)\n",
        "    if gdf_comm is not None and community_name:\n",
        "        comm = gdf_comm[gdf_comm[\"NAME_1\"].str.strip().str.lower() == community_name.strip().lower()]\n",
        "        if not comm.empty:\n",
        "            comm.boundary.plot(ax=ax1, color=\"red\", linewidth=2)\n",
        "    ax1.set_title(f\"{title_prefix} in Spain\", fontsize=14)\n",
        "    ax1.set_xlabel(\"Longitude\")\n",
        "    ax1.set_ylabel(\"Latitude\")\n",
        "    ax1.legend(title=\"Province\", fontsize=9)\n",
        "\n",
        "    # --- Zoomed-in community map ---\n",
        "    if community_name and gdf_comm is not None:\n",
        "        comm = gdf_comm[gdf_comm[\"NAME_1\"].str.strip().str.lower() == community_name.strip().lower()]\n",
        "        if comm.empty:\n",
        "            print(f\"Community '{community_name}' not found for zoomed-in map.\")\n",
        "        else:\n",
        "            minx, miny, maxx, maxy = comm.total_bounds\n",
        "            ax2.set_xlim(minx - 0.1, maxx + 0.1)\n",
        "            ax2.set_ylim(miny - 0.1, maxy + 0.1)\n",
        "            gdf_prov.boundary.plot(ax=ax2, color=\"black\", linewidth=0.5)\n",
        "            if gdf_muni is not None:\n",
        "                gdf_muni.boundary.plot(ax=ax2, color=\"gray\", linewidth=0.2, alpha=0.3)\n",
        "            comm.boundary.plot(ax=ax2, color=\"red\", linewidth=2)\n",
        "            gdf_comm_points = gdf_occurrences[gdf_occurrences.within(comm.geometry.union_all())] if not gdf_occurrences.empty else gdf_occurrences\n",
        "            for prov, color in province_colors.items():\n",
        "                subset = gdf_comm_points[gdf_comm_points[\"province_assigned\"] == prov]\n",
        "                subset.plot(ax=ax2, color=color, markersize=30, alpha=0.7, label=prov)\n",
        "            ax2.set_title(f\"{title_prefix} in {community_name}\", fontsize=14)\n",
        "            ax2.set_xlabel(\"Longitude\")\n",
        "            ax2.set_ylabel(\"Latitude\")\n",
        "            ax2.legend(title=\"Province\", fontsize=9)\n",
        "    else:\n",
        "        ax2.axis(\"off\")  # hide if no zoom map\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5️⃣ Example workflow\n",
        "# ================================\n",
        "if __name__ == \"__main__\":\n",
        "    species = scientific_name\n",
        "    community = \"Comunidad de Madrid\"\n",
        "\n",
        "    communities_file = \"shapefiles/gadm41_ESP_1.shp\"\n",
        "    provinces_file = \"shapefiles/gadm41_ESP_2.shp\"\n",
        "    municipalities_file = \"shapefiles/gadm41_ESP_3.shp\"\n",
        "\n",
        "    # --- GBIF ---\n",
        "    gdf_gbif = query_gbif_by_community_bbox(species, community, communities_file, limit=1000)\n",
        "    gdf_gbif = assign_admin_levels(gdf_gbif, provinces_file, municipalities_file)\n",
        "\n",
        "    # --- Germplasm bank ---\n",
        "    gdf_germplasm = gpd.GeoDataFrame(\n",
        "        df_germplasm,\n",
        "        geometry=[Point(xy) for xy in zip(df[\"decimalLongitude\"], df[\"decimalLatitude\"])],\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    gdf_germplasm = filter_within_community(gdf_germplasm, communities_file, community)\n",
        "    gdf_germplasm = assign_admin_levels(gdf_germplasm, provinces_file, municipalities_file)\n",
        "\n",
        "    # --- Coverage comparison ---\n",
        "    province_cov, municipality_cov, gbif_provs, germ_provs, gbif_munis, germ_munis = calculate_coverage_with_names(gdf_gbif, gdf_germplasm, plot=True)\n",
        "    print(f\"Germplasm bank covers {province_cov:.1f}% of GBIF provinces\")\n",
        "    print(f\"GBIF provinces: {gbif_provs}\")\n",
        "    print(f\"Germplasm provinces: {germ_provs}\")\n",
        "    print(f\"Germplasm bank covers {municipality_cov:.1f}% of GBIF municipalities\")\n",
        "    print(f\"GBIF municipalities: {gbif_munis}\")\n",
        "    print(f\"Germplasm municipalities: {germ_munis}\")\n",
        "\n",
        "    # --- Plots ---\n",
        "    plot_dataset_separately(\n",
        "        gdf_gbif,\n",
        "        provinces_file,\n",
        "        municipalities_file,\n",
        "        communities_file,\n",
        "        community_name=community,\n",
        "        title_prefix=\"GBIF occurrences\"\n",
        "    )\n",
        "    plot_dataset_separately(\n",
        "        gdf_germplasm,\n",
        "        provinces_file,\n",
        "        municipalities_file,\n",
        "        communities_file,\n",
        "        community_name=community,\n",
        "        title_prefix=\"Germplasm bank occurrences\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f66789cd",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# CLEAR NOTEBOOK CACHE\n",
        "\n",
        "The code below will erase the cache and force this Jupyter Notebook to be reloaded from-scratch when you click the \"reload\" button.\n",
        "\n",
        "You will lose all work and all code if you do this!  You have been warned :-)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3faa7cff",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"\"\"\n",
        "<button type=\"button\" id=\"button_for_indexeddb\">Clear JupyterLite local storage</button>\n",
        "<script>\n",
        "window.button_for_indexeddb.onclick = function(e) {\n",
        "    window.indexedDB.open('JupyterLite Storage').onsuccess = function(e) {\n",
        "        // There are also other tables that I'm not clearing:\n",
        "        // \"counters\", \"settings\", \"local-storage-detect-blob-support\"\n",
        "        let tables = [\"checkpoints\", \"files\"];\n",
        "\n",
        "        let db = e.target.result;\n",
        "        let t = db.transaction(tables, \"readwrite\");\n",
        "\n",
        "        function clearTable(tablename) {\n",
        "            let st = t.objectStore(tablename);\n",
        "            st.count().onsuccess = function(e) {\n",
        "                console.log(\"Deleting \" + e.target.result + \" entries from \" + tablename + \"...\");\n",
        "                st.clear().onsuccess = function(e) {\n",
        "                    console.log(tablename + \" is cleared!\");\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for (let tablename of tables) {\n",
        "            clearTable(tablename);\n",
        "        }\n",
        "    }\n",
        "};\n",
        "</script>\n",
        "\"\"\"))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
